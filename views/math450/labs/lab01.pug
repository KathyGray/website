extends ../../lab
include ../../mixins/url.pug
include ../../mixins/title.pug
include ../../mixins/userinfo.pug
include ../../mixins/warning.pug
include ../../mixins/shortanswer.pug
include ../../mixins/multiplechoice.pug

block content
    +title("MATH 450 Chapter 2-Part 1 Notes")
    +warning("Leaving or refreshing this page might lose your work.")

    form(action="/math450/labs/submit" method="post" class="needs-validation" novalidate)
        input(type="hidden" name="_csrf" value= csrfToken)
        input(type="hidden" name="lab" value= labId)
        // Due date is in UTC
        input(type="hidden" name="duedate" value="2020-06-25T07:00:00")
        +userinfo()

        h4 Subjective Worlds of Frequentist and Bayesian Statistics

        h4 Bayes' Theorem

        a: img(src="/math105/bayes_th.PNG" alt="Bayes", style='width:700px;height:400px;')

        p.

            In Math 350 you learned about Bayes' theorem. We will review that theorem briefly before we dive into other topics that lead up to Bayesian statistics. As you might have guessed, Bayesian statistics is built on Bayes' theorem.

        p. 

            Please take about 20 minutes to read the following article about Bayes' theorem

        p.

            #[+url("https://blogs.scientificamerican.com/cross-check/bayes-s-theorem-what-s-the-big-deal/")]

        p.

            Bayes' Theorem:

        p.

            Suppose that we are interested in which of several events #[i A#[sub 1]],#[i A#[sub 2]] ,...,#[i A#[sub k]] will occur and that we will get to observe some other event #[i B].  If $$\textmd{P}(B|A_{i})$$ is available for each #[i i], then Bayes' theorem is a useful formula for computing the conditional probabilities of the #[i A#[sub i]] events given #[i B].

        p.

            Theorem: Law of total Probability and Bayes' Theorem:

            #[+url("https://media.csuchico.edu/media/Math+450-Chapter+2+Bayes/0_9h6v3hs7")]

            Suppose that the events #[i A#[sub 1]],#[i A#[sub 2]] ,...,#[i A#[sub k]] form a partition of the space #[i S] and P(#[i A#[sub j]])>0 for #[i j]=1,...,#[i k].  Then, for every event #[i B] in #[i S], $$\textmd{P}(B)=\sum^{k}_{j=1}\textmd{P}(A_{j})\textmd{P}(B|A_{j})$$

        p. 

            Theorem Bayes' Theorem

            Let #[i A#[sub 1]],#[i A#[sub 2]] ,...,#[i A#[sub k]] form a partition of the space #[i S] and P(#[i A#[sub j]])>0 for #[i j]=1,...,#[i k].  Then, for every event #[i B] in #[i S], $$S=A_{1}\cup A_{2}\cup \cdots \cup A_{k}$$

            and $$A_{i}\cap A_{j}=\emptyset, i\neq j$$


        p.

            Suppose that #[i B] is an event, then #[i B]  is the union of $k$ mutually exclusive events: $$B=\left(A_{1}  \cap B\right)\cup\left(A_{2} \cap B\right)\cup \cdots\cup\left(A_{k}\cap B\right)$$

        p. 

            Thus, $$P(B)=P\left(A_{1}  \cap B\right)\cup P\left(A_{2} \cap B\right)\cup \cdots\cup P\left(A_{k}\cap B\right)$$

        p.

            If P#[i B]>0, then we have that $$\textmd{P}\left(A_{j}|B\right)=\frac{P(B|A_{j})P(A_{j})}{\sum P(B|A_{i})P(A_{i})}$$

        p.

            The conditional probability P(#[i A #[sub j]]|B) is often called the #[strong posterior probability] of #[i A #[sub j]] because it is the probability of #[i A #[sub j]] occurring after we know that A has occurred.  The probability of #[i A #[sub j]] is called the prior probability because P(#[i A #[sub j]]) is the probability of #[i A #[sub j]] occurring before we know the outcome of #[i B].

        h4 Example:

        p.

            #[+url("https://media.csuchico.edu/media/Math+450-Chapter+2-Bayes+Example/0_d6kcz4p7")]

        p.

            Suppose that you are walking down the street and notice that the Department of Public Health is giving a free medical test for a certain disease.  The test is 90 percent reliable in the following sense:  If a person has the disease, there is a probability of .9 that the test will yield a positive response; whereas, if a person does not have the disease, there is a probability of .1 that the test will give a positive response.

        p.

            Data indicate that your chances of having the disease  are only 1 in 10,000.  However, since the test costs you nothing, and is fast and harmless, you decide to stop and take the test.  A few days later you learn that you had a positive response to the test.  Now, what is the probability that you have the disease?

        p. 
        
            This example illustrates the idea of Bayes' Theorem.  

        +shortanswer("answer01", "We have a piece of information that we know which is", "2")

        +shortanswer("answer02", "and there are (at least) two disjoint events which are", "2")

        +shortanswer("answer03", " What is the probability that, given that the person tested positive for the disease, he actually has the disease?", "1")

        h4 You try it:

        p. 

            In a certain factory, machines I, II, and III are all producing springs of the same length.  Of their production,
            machines I, II, and III produce 2%, 1%, and 3% defective springs, respectively.  Of the total production of springs in the factory, machine I produces 35%, machine II produces 25%, and machine III produces 40%.  If one spring is selected at random is defective, find the conditional
            probability that it was produced by machine III.

        +shortanswer("answer04", " If one spring selected at random is defective, find the conditional probability that it was produced by maching III.", "1")  

        button(class="btn btn-md btn-primary" type="submit") submit
